#!/usr/bin/env python
"""
ê°„ì†Œí™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • - ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ìš©
í•„ìˆ˜ í…Œì´ë¸”ë§Œ ìƒì„±, ì‹œê³„ì—´ ë°ì´í„°ëŠ” InfluxDBì—ì„œ ì§ì ‘ ì²˜ë¦¬
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.db import DatabaseManager
from core.logger import logger

def create_streamlined_tables():
    """ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ìš© ê°„ì†Œí™”ëœ í…Œì´ë¸” ìƒì„±"""
    db = DatabaseManager()
    
    try:
        # ê¸°ë³¸ íšŒì‚¬ í…Œì´ë¸” í™•ì¸
        check_query = "SHOW TABLES LIKE 'companies'"
        if not db.fetch_one(check_query):
            logger.error("companies í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
            return False
        
        # ì„œë²„ í…Œì´ë¸” (íšŒì‚¬ë³„ ë””ë°”ì´ìŠ¤ ê´€ë¦¬)
        create_servers = """
        CREATE TABLE IF NOT EXISTS servers (
            server_no INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(30) NOT NULL,
            server_iphost VARCHAR(20) DEFAULT NULL COMMENT 'ë””ë°”ì´ìŠ¤ ID',
            server_name VARCHAR(100) DEFAULT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            is_active BOOLEAN DEFAULT TRUE,
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            INDEX idx_domain_device (company_domain, server_iphost),
            INDEX idx_active (is_active)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ì„œë²„/ë””ë°”ì´ìŠ¤ ì •ë³´ ê´€ë¦¬'
        """
        db.execute_query(create_servers)
        logger.info("servers í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ì„¤ì • í…Œì´ë¸” (íšŒì‚¬ë³„/ì„œë²„ë³„ ì„¤ì • ê´€ë¦¬)
        create_configurations = """
        CREATE TABLE IF NOT EXISTS configurations (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NULL,
            config_type VARCHAR(50) NOT NULL COMMENT 'ì„¤ì • ìœ í˜• (aggregation, excluded_devices ë“±)',
            config_key VARCHAR(100) NOT NULL COMMENT 'ì„¤ì • í‚¤',
            config_value TEXT NOT NULL COMMENT 'ì„¤ì • ê°’ (JSON ê°€ëŠ¥)',
            is_active BOOLEAN DEFAULT TRUE,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            UNIQUE KEY uk_config (company_domain, server_no, config_type, config_key),
            INDEX idx_type_key (config_type, config_key),
            INDEX idx_active (is_active)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´'
        """
        db.execute_query(create_configurations)
        logger.info("configurations í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ëª¨ë¸ ì„±ëŠ¥ í…Œì´ë¸” (í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ì¶”ì )
        create_model_performance = """
        CREATE TABLE IF NOT EXISTS model_performance (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NOT NULL,
            application VARCHAR(100) NOT NULL COMMENT 'ì• í”Œë¦¬ì¼€ì´ì…˜ëª… (systemì€ ì‹œìŠ¤í…œ ëª¨ë¸)',
            resource_type VARCHAR(50) NOT NULL COMMENT 'cpu, mem, disk',
            model_type VARCHAR(50) NOT NULL COMMENT 'random_forest, gradient_boosting ë“±',
            mae DOUBLE NOT NULL COMMENT 'í‰ê·  ì ˆëŒ€ ì˜¤ì°¨',
            rmse DOUBLE NOT NULL COMMENT 'í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨',
            r2_score DOUBLE NOT NULL COMMENT 'RÂ² ì ìˆ˜',
            feature_importance JSON COMMENT 'íŠ¹ì„± ì¤‘ìš”ë„',
            trained_at DATETIME NOT NULL COMMENT 'í•™ìŠµ ì‹œê°„',
            version VARCHAR(50) NOT NULL COMMENT 'ëª¨ë¸ ë²„ì „',
            device_id VARCHAR(100) DEFAULT '' COMMENT 'ë””ë°”ì´ìŠ¤ ID',
            cache_path VARCHAR(500) DEFAULT NULL COMMENT 'ëª¨ë¸ íŒŒì¼ ê²½ë¡œ',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            INDEX idx_model (company_domain, server_no, application, resource_type),
            INDEX idx_device_id (device_id),
            INDEX idx_trained_at (trained_at)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ëª¨ë¸ ì„±ëŠ¥ ë° ë©”íƒ€ë°ì´í„°'
        """
        db.execute_query(create_model_performance)
        logger.info("model_performance í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸” (ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ë§Œ ì €ì¥)
        create_predictions = """
        CREATE TABLE IF NOT EXISTS predictions (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NOT NULL,
            prediction_time DATETIME NOT NULL COMMENT 'ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œê°„',
            target_time DATETIME NOT NULL COMMENT 'ì˜ˆì¸¡ ëŒ€ìƒ ì‹œê°„',
            resource_type VARCHAR(50) NOT NULL COMMENT 'cpu, mem, disk',
            predicted_value DOUBLE NOT NULL COMMENT 'ì˜ˆì¸¡ê°’',
            actual_value DOUBLE NULL COMMENT 'ì‹¤ì œê°’ (ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)',
            error DOUBLE NULL COMMENT 'ì˜ˆì¸¡ ì˜¤ì°¨',
            model_version VARCHAR(100) NOT NULL COMMENT 'ì‚¬ìš©ëœ ëª¨ë¸ ë²„ì „',
            confidence_score DOUBLE DEFAULT NULL COMMENT 'ì˜ˆì¸¡ ì‹ ë¢°ë„',
            batch_id VARCHAR(100) DEFAULT NULL COMMENT 'ë°°ì¹˜ ID',
            device_id VARCHAR(100) DEFAULT '' COMMENT 'ë””ë°”ì´ìŠ¤ ID',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            INDEX idx_prediction (company_domain, server_no, resource_type, target_time),
            INDEX idx_device_id (device_id),
            INDEX idx_accuracy (target_time, actual_value),
            INDEX idx_batch (batch_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥'
        """
        db.execute_query(create_predictions)
        logger.info("predictions í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ì•Œë¦¼ í…Œì´ë¸” (ì„ê³„ê°’ ë„ë‹¬ ì•Œë¦¼)
        create_alerts = """
        CREATE TABLE IF NOT EXISTS alerts (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NOT NULL,
            resource_type VARCHAR(50) NOT NULL COMMENT 'cpu, mem, disk',
            threshold DOUBLE NOT NULL COMMENT 'ì„¤ì •ëœ ì„ê³„ê°’',
            crossing_time DATETIME NOT NULL COMMENT 'ì„ê³„ê°’ ë„ë‹¬ ì˜ˆìƒ ì‹œê°„',
            time_to_threshold DOUBLE NOT NULL COMMENT 'ì„ê³„ê°’ê¹Œì§€ ë‚¨ì€ ì‹œê°„(ì‹œ)',
            current_value DOUBLE NOT NULL COMMENT 'í˜„ì¬ ê°’',
            predicted_value DOUBLE NOT NULL COMMENT 'ì˜ˆì¸¡ê°’',
            is_notified BOOLEAN DEFAULT FALSE COMMENT 'ì•Œë¦¼ ë°œì†¡ ì—¬ë¶€',
            notified_at DATETIME NULL COMMENT 'ì•Œë¦¼ ë°œì†¡ ì‹œê°„',
            alert_level VARCHAR(20) DEFAULT 'warning' COMMENT 'info, warning, critical',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            batch_id VARCHAR(100) DEFAULT NULL,
            device_id VARCHAR(100) DEFAULT '' COMMENT 'ë””ë°”ì´ìŠ¤ ID',
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            INDEX idx_alert (company_domain, server_no, resource_type, created_at),
            INDEX idx_device_id (device_id),
            INDEX idx_notification (is_notified, created_at),
            INDEX idx_level (alert_level)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ì‹œìŠ¤í…œ ì•Œë¦¼ ê´€ë¦¬'
        """
        db.execute_query(create_alerts)
        logger.info("alerts í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ì‘ì—… ë¡œê·¸ í…Œì´ë¸” (ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ì¶”ì )
        create_job_logs = """
        CREATE TABLE IF NOT EXISTS job_logs (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NULL COMMENT 'NULLì´ë©´ ì „ì²´ íšŒì‚¬ ì‘ì—…',
            job_type VARCHAR(50) NOT NULL COMMENT 'data_collection, model_training, prediction ë“±',
            job_status VARCHAR(20) NOT NULL COMMENT 'running, completed, failed',
            start_time DATETIME NOT NULL,
            end_time DATETIME NULL,
            duration_seconds INT NULL COMMENT 'ì‹¤í–‰ ì‹œê°„(ì´ˆ)',
            records_processed INT DEFAULT 0 COMMENT 'ì²˜ë¦¬ëœ ë ˆì½”ë“œ ìˆ˜',
            cache_files_created INT DEFAULT 0 COMMENT 'ìƒì„±ëœ ìºì‹œ íŒŒì¼ ìˆ˜',
            error_message TEXT NULL COMMENT 'ì˜¤ë¥˜ ë©”ì‹œì§€',
            details JSON NULL COMMENT 'ìƒì„¸ ì •ë³´',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            INDEX idx_job (company_domain, server_no, job_type, start_time),
            INDEX idx_status (job_status, start_time),
            INDEX idx_type (job_type)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='ì‘ì—… ì‹¤í–‰ ë¡œê·¸'
        """
        db.execute_query(create_job_logs)
        logger.info("job_logs í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        # ìºì‹œ ë©”íƒ€ë°ì´í„° í…Œì´ë¸” (íŒŒì¼ ìºì‹œ ê´€ë¦¬)
        create_cache_metadata = """
        CREATE TABLE IF NOT EXISTS cache_metadata (
            id INT AUTO_INCREMENT PRIMARY KEY,
            company_domain VARCHAR(50) NOT NULL,
            server_no INT NOT NULL,
            cache_type VARCHAR(50) NOT NULL COMMENT 'jvm_data, sys_data, impacts, features',
            cache_key VARCHAR(200) NOT NULL COMMENT 'ìºì‹œ í‚¤ (ì‹œê°„ ë²”ìœ„ ë“±)',
            file_path VARCHAR(500) NOT NULL COMMENT 'íŒŒì¼ ê²½ë¡œ',
            file_size_bytes BIGINT DEFAULT 0 COMMENT 'íŒŒì¼ í¬ê¸°',
            record_count INT DEFAULT 0 COMMENT 'ë ˆì½”ë“œ ìˆ˜',
            start_time DATETIME NOT NULL COMMENT 'ë°ì´í„° ì‹œì‘ ì‹œê°„',
            end_time DATETIME NOT NULL COMMENT 'ë°ì´í„° ì¢…ë£Œ ì‹œê°„',
            expires_at DATETIME NOT NULL COMMENT 'ë§Œë£Œ ì‹œê°„',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            device_id VARCHAR(100) DEFAULT '' COMMENT 'ë””ë°”ì´ìŠ¤ ID',
            FOREIGN KEY (company_domain) REFERENCES companies(company_domain),
            FOREIGN KEY (server_no) REFERENCES servers(server_no),
            UNIQUE KEY uk_cache (company_domain, server_no, cache_type, cache_key),
            INDEX idx_expires (expires_at),
            INDEX idx_device (device_id),
            INDEX idx_type_time (cache_type, start_time)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        COMMENT='íŒŒì¼ ìºì‹œ ë©”íƒ€ë°ì´í„°'
        """
        db.execute_query(create_cache_metadata)
        logger.info("cache_metadata í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ")
        
        logger.info("ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return False
    finally:
        db.close()

def insert_default_streaming_configs():
    """ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ìš© ê¸°ë³¸ ì„¤ì • ì‚½ì…"""
    db = DatabaseManager()
    
    try:
        # 1. ê¸°ì¡´ íšŒì‚¬ ì¤‘ ì²« ë²ˆì§¸ íšŒì‚¬ë¥¼ ê¸°ë³¸ ì„¤ì • ëŒ€ìƒìœ¼ë¡œ ì„ íƒ
        existing_companies = db.fetch_all("SELECT company_domain FROM companies WHERE is_active = 1 ORDER BY registered_at LIMIT 5")
        
        if not existing_companies:
            logger.error("í™œì„±í™”ëœ íšŒì‚¬ê°€ ì—†ì–´ ê¸°ë³¸ ì„¤ì •ì„ ì‚½ì…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 'javame' íšŒì‚¬ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ íšŒì‚¬ ì‚¬ìš©
        target_company = None
        for company_row in existing_companies:
            company_domain = company_row[0]
            if company_domain == 'javame':
                target_company = company_domain
                break
        
        if not target_company:
            target_company = existing_companies[0][0]
        
        logger.info(f"ê¸°ë³¸ ì„¤ì • ì‚½ì… ëŒ€ìƒ íšŒì‚¬: '{target_company}'")
        
        # 2. ê¸°ë³¸ ì„¤ì • ë°ì´í„°
        global_configs = [
            # ì‹œê°„ ì •ë ¬ ì„¤ì • (ê°€ì¥ ì¤‘ìš”)
            ('time_alignment', 'time_alignment_minutes', '1'),
            ('time_alignment', 'aggregation_window_seconds', '30'),
            ('time_alignment', 'time_tolerance_minutes', '2'),
            ('time_alignment', 'max_prediction_age_hours', '48'),
            
            # ìºì‹œ ì„¤ì •
            ('cache', 'default_ttl_hours', '6'),
            ('cache', 'max_file_age_hours', '48'),
            ('cache', 'cleanup_interval_hours', '12'),
            
            # ë°ì´í„° ìˆ˜ì§‘ ì„¤ì •
            ('collection', 'training_data_days', '3'),
            ('collection', 'latest_data_minutes', '30'),
            ('collection', 'influxdb_timeout_seconds', '60'),
            
            # ì§‘ê³„ ì„¤ì • (CPU ì‚¬ìš©ë¥  ê³„ì‚° í¬í•¨)
            ('aggregation', 'cpu', '{"method": "max", "reason": "í”¼í¬ ì‚¬ìš©ë¥ ì´ ì¤‘ìš”", "calculation": "100 - usage_idle"}'),
            ('aggregation', 'mem', '{"method": "last", "reason": "í˜„ì¬ ìƒíƒœê°€ ì¤‘ìš”"}'),
            ('aggregation', 'disk', '{"method": "last", "reason": "ëˆ„ì  ì‚¬ìš©ëŸ‰"}'),
            
            # ì œì™¸ ëª©ë¡
            ('excluded', 'gateways', 'diskio,net,sensors,swap,system,http,unknown_service,ì…êµ¬,jvm'),
            ('excluded', 'devices', 'nhnacademy-Inspiron-14-5420,24e124743d011875,24e124136d151368'),
            
            # ëª¨ë¸ ì„¤ì •
            ('model', 'retrain_threshold_hours', '24'),
            ('model', 'min_training_records', '100'),
            ('model', 'feature_cache_enabled', 'true'),
            
            # ì•Œë¦¼ ì„¤ì •
            ('alert', 'cpu_threshold', '80.0'),
            ('alert', 'memory_threshold', '80.0'),
            ('alert', 'disk_threshold', '85.0'),
            ('alert', 'notification_cooldown_minutes', '60')
        ]
        
        # 3. ê¸°ì¡´ ì„¤ì • í™•ì¸ í›„ í•„ìš”ì‹œì—ë§Œ ì‚½ì…
        check_query = """
        SELECT COUNT(*) FROM configurations 
        WHERE company_domain = %s AND config_type = %s AND config_key = %s
        """
        
        insert_query = """
        INSERT INTO configurations 
        (company_domain, server_no, config_type, config_key, config_value, is_active)
        VALUES (%s, NULL, %s, %s, %s, TRUE)
        """
        
        inserted_count = 0
        
        for config_type, config_key, config_value in global_configs:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing = db.fetch_one(check_query, (target_company, config_type, config_key))
            
            if not existing or existing[0] == 0:
                # ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì‚½ì…
                if db.execute_query(insert_query, (target_company, config_type, config_key, config_value)):
                    inserted_count += 1
                    logger.debug(f"ì„¤ì • ì‚½ì…: {config_type}.{config_key} = {config_value}")
                else:
                    logger.warning(f"ì„¤ì • ì‚½ì… ì‹¤íŒ¨: {config_type}.{config_key}")
            else:
                logger.debug(f"ì„¤ì • ì´ë¯¸ ì¡´ì¬: {config_type}.{config_key}")
        
        logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ê¸°ë³¸ ì„¤ì • ì²˜ë¦¬ ì™„ë£Œ: {inserted_count}ê°œ ì‹ ê·œ ì‚½ì… (ëŒ€ìƒ: {target_company})")
        return True
        
    except Exception as e:
        logger.error(f"ê¸°ë³¸ ì„¤ì • ì‚½ì… ì˜¤ë¥˜: {e}")
        return False
    finally:
        db.close()

def cleanup_legacy_tables():
    """ê¸°ì¡´ ë¶ˆí•„ìš”í•œ í…Œì´ë¸” ì •ë¦¬ (ì„ íƒì )"""
    db = DatabaseManager()
    
    # ì£¼ì˜: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë°ì´í„° ë°±ì—… í›„ ì‹¤í–‰
    legacy_tables = [
        'jvm_metrics',
        'system_resources', 
        'application_impact',
        'feature_data'
    ]
    
    try:
        for table in legacy_tables:
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            check_query = f"SHOW TABLES LIKE '{table}'"
            if db.fetch_one(check_query):
                logger.warning(f"ê¸°ì¡´ í…Œì´ë¸” ë°œê²¬: {table}")
                logger.warning(f"ë°ì´í„° ë°±ì—… í›„ 'DROP TABLE {table}' ì‹¤í–‰ì„ ê³ ë ¤í•˜ì„¸ìš”")
                
                # ìë™ ì‚­ì œëŠ” í•˜ì§€ ì•ŠìŒ (ì•ˆì „ì„ ìœ„í•´)
                # drop_query = f"DROP TABLE IF EXISTS {table}"
                # db.execute_query(drop_query)
        
        logger.info("ê¸°ì¡´ í…Œì´ë¸” ì •ë¦¬ í™•ì¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"ê¸°ì¡´ í…Œì´ë¸” ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False
    finally:
        db.close()

def validate_streaming_setup():
    """ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ì„¤ì • ê²€ì¦"""
    db = DatabaseManager()
    
    try:
        required_tables = [
            'companies', 'servers', 'configurations', 
            'model_performance', 'predictions', 'alerts',
            'job_logs', 'cache_metadata'
        ]
        
        missing_tables = []
        for table in required_tables:
            check_query = f"SHOW TABLES LIKE '{table}'"
            if not db.fetch_one(check_query):
                missing_tables.append(table)
        
        if missing_tables:
            logger.error(f"í•„ìˆ˜ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {missing_tables}")
            return False
        
        # ì„¤ì • í™•ì¸ - ì‹¤ì œ íšŒì‚¬ ë„ë©”ì¸ì—ì„œ í™•ì¸
        config_query = """
        SELECT COUNT(*) FROM configurations 
        WHERE config_type IN ('time_alignment', 'cache', 'aggregation', 'excluded', 'model', 'alert')
        """
        config_result = db.fetch_one(config_query)
        config_count = config_result[0] if config_result else 0
        
        logger.info(f"ë°œê²¬ëœ ê¸°ë³¸ ì„¤ì •: {config_count}ê°œ")
        
        # ìµœì†Œ 5ê°œ ì´ìƒì˜ ì„¤ì •ì´ ìˆìœ¼ë©´ í†µê³¼
        if config_count < 5:
            logger.warning(f"ê¸°ë³¸ ì„¤ì •ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({config_count}ê°œ). ìµœì†Œ 5ê°œ í•„ìš”.")
            
            # ì„¤ì • ìœ í˜•ë³„ ìƒì„¸ í™•ì¸
            detail_query = """
            SELECT config_type, COUNT(*) 
            FROM configurations 
            GROUP BY config_type
            """
            details = db.fetch_all(detail_query)
            
            if details:
                logger.info("í˜„ì¬ ì„¤ì • ìœ í˜•ë³„ ê°œìˆ˜:")
                for config_type, count in details:
                    logger.info(f"  {config_type}: {count}ê°œ")
            
            return False
        
        logger.info("ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        return False
    finally:
        db.close()

if __name__ == "__main__":
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹œì‘")
    
    success = True
    
    # 1. í…Œì´ë¸” ìƒì„±
    if not create_streamlined_tables():
        success = False
    
    # 2. ê¸°ë³¸ ì„¤ì • ì‚½ì…
    if success and not insert_default_streaming_configs():
        success = False
    
    # 3. ê¸°ì¡´ í…Œì´ë¸” ì •ë¦¬ í™•ì¸
    if success:
        cleanup_legacy_tables()
    
    # 4. ì„¤ì • ê²€ì¦
    if success and not validate_streaming_setup():
        success = False
    
    if success:
        logger.info("ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")
        print("âœ… ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ë¡œ ì„±ê³µì ìœ¼ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("")
        print("ğŸ“Š ë³€ê²½ì‚¬í•­:")
        print("  - jvm_metrics, system_resources â†’ InfluxDB ì§ì ‘ ì¡°íšŒ")
        print("  - application_impact, feature_data â†’ íŒŒì¼ ìºì‹±")
        print("  - í•„ìˆ˜ í…Œì´ë¸”ë§Œ ìœ ì§€í•˜ì—¬ DB ë¶€í•˜ ìµœì†Œí™”")
        print("")
        print("ğŸ—‚ï¸ ìºì‹œ ë””ë ‰í† ë¦¬:")
        print("  - cache/{company}/{device}/")
        print("    â”œâ”€â”€ raw ë°ì´í„° ìºì‹œ (jvm_*.pkl, sys_*.pkl)")
        print("    â”œâ”€â”€ impacts/ (ì˜í–¥ë„ ìºì‹œ)")
        print("    â””â”€â”€ features/ (íŠ¹ì„± ìºì‹œ)")
    else:
        logger.error("ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨")
        sys.exit(1)