#!/usr/bin/env python
"""
JVM ë©”íŠ¸ë¦­ ê¸°ë°˜ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡ - ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
InfluxDB ì§ì ‘ ì²˜ë¦¬ ë° íŒŒì¼ ìºì‹± ê¸°ë°˜ì˜ íš¨ìœ¨ì ì¸ ë©€í‹° í…Œë„ŒíŠ¸ ì‹œìŠ¤í…œ
"""
import os
import sys
import argparse
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ íŒ¨ìŠ¤ì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("í™˜ê²½ ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì„¤ì • í•„ìš”")
except Exception as e:
    print(f"í™˜ê²½ ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")

from core.logger import logger, set_context
from scheduler.global_scheduler import StreamingGlobalScheduler

def validate_streaming_environment():
    """ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ í™˜ê²½ë³€ìˆ˜ ìœ íš¨ì„± ê²€ì‚¬"""
    required_env = [
        'MYSQL_HOST', 'MYSQL_USER', 'MYSQL_PASSWORD', 'MYSQL_DATABASE',
        'INFLUXDB_URL', 'INFLUXDB_TOKEN'
    ]
    
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        logger.error(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_env}")
        logger.error("ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:")
        for env in required_env:
            logger.error(f"  - {env}")
        return False
    
    return True

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
    logging.getLogger().setLevel(getattr(logging, log_level))
    
    logger.info(f"ë¡œê¹… ë ˆë²¨ ì„¤ì •: {log_level}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='JVM ë©”íŠ¸ë¦­ ì˜ˆì¸¡ ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ì‹œìŠ¤í…œ')
    parser.add_argument('--mode', choices=['scheduler', 'health-check', 'config-test', 'status', 'migrate'], 
                       default='scheduler', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ì„¤ì •ë§Œ í™•ì¸')
    parser.add_argument('--cache-cleanup', action='store_true', help='ìºì‹œ ì •ë¦¬ í›„ ì¢…ë£Œ')
    
    args = parser.parse_args()
    
    try:
        # ë¡œê¹… ì„¤ì •
        setup_logging()
        
        # ê¸€ë¡œë²Œ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        set_context(company_domain="streaming_global")
        
        logger.info("JVM ë©”íŠ¸ë¦­ ì˜ˆì¸¡ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ ì‹œì‘")
        logger.info(f"ì‹¤í–‰ ëª¨ë“œ: {args.mode}")
        
        # ëª¨ë“œë³„ ì‹¤í–‰
        if args.mode == 'config-test':
            run_config_test()
        elif args.mode == 'health-check':
            if not validate_streaming_environment():
                sys.exit(1)
            run_health_check()
        elif args.mode == 'status':
            if not validate_streaming_environment():
                sys.exit(1)
            run_status_check()
        elif args.mode == 'migrate':
            run_migration_setup()
        elif args.mode == 'scheduler':
            if args.cache_cleanup:
                run_cache_cleanup_only()
            elif args.dry_run:
                logger.info("ë“œë¼ì´ëŸ° ëª¨ë“œ: ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •ë§Œ í™•ì¸")
                scheduler = StreamingGlobalScheduler()
                logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì„±ê³µ")
                status = scheduler.get_status()
                logger.info(f"ì‹œìŠ¤í…œ ìƒíƒœ: {status}")
                return
            else:
                if not validate_streaming_environment():
                    sys.exit(1)
                run_streaming_scheduler()
        else:
            logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {args.mode}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•œ ì¢…ë£Œ")
    except Exception as e:
        logger.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

def run_config_test():
    """ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • í…ŒìŠ¤íŠ¸"""
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    logger.info("í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
    logger.info(f"MySQL í˜¸ìŠ¤íŠ¸: {os.getenv('MYSQL_HOST', 'localhost')}")
    logger.info(f"MySQL ë°ì´í„°ë² ì´ìŠ¤: {os.getenv('MYSQL_DATABASE', 'jvm_metrics')}")
    logger.info(f"InfluxDB URL: {os.getenv('INFLUXDB_URL', 'http://localhost:8086')}")
    logger.info(f"InfluxDB ì¡°ì§: {os.getenv('INFLUXDB_ORG', 'javame')}")
    
    # ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ì¼€ì¤„ ì„¤ì • í™•ì¸
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ì¼€ì¤„ ì„¤ì •:")
    logger.info(f"íšŒì‚¬ ê°ì§€ ê°„ê²©: {os.getenv('DISCOVERY_INTERVAL', '60')}ë¶„")
    logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ê°„ê²©: {os.getenv('STREAMING_INTERVAL', '30')}ë¶„")
    logger.info(f"ëª¨ë¸ í•™ìŠµ ê°„ê²©: {os.getenv('MODEL_TRAINING_INTERVAL', '360')}ë¶„")
    logger.info(f"ì˜ˆì¸¡ ê°„ê²©: {os.getenv('PREDICTION_INTERVAL', '60')}ë¶„")
    logger.info(f"ìºì‹œ ì •ë¦¬ ê°„ê²©: {os.getenv('CACHE_CLEANUP_INTERVAL', '720')}ë¶„")
    logger.info(f"í—¬ìŠ¤ ì²´í¬ ê°„ê²©: {os.getenv('HEALTH_CHECK_INTERVAL', '15')}ë¶„")
    
    # ìºì‹œ ì„¤ì • í™•ì¸
    logger.info("ìºì‹œ ì„¤ì •:")
    logger.info(f"ìºì‹œ TTL: {os.getenv('CACHE_TTL_HOURS', '6')}ì‹œê°„")
    logger.info(f"ìµœëŒ€ ìºì‹œ ë³´ê´€: {os.getenv('MAX_CACHE_AGE_HOURS', '48')}ì‹œê°„")
    logger.info(f"ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬: {os.getenv('MAX_WORKERS', '3')}ê°œ")
    logger.info(f"ì¦‰ì‹œ ì‹¤í–‰ ì—¬ë¶€: {os.getenv('RUN_IMMEDIATE', 'true')}")
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
    cache_base = os.path.join(os.getcwd(), "cache")
    logger.info(f"ìºì‹œ ê¸°ë³¸ ë””ë ‰í† ë¦¬: {cache_base}")
    
    if os.path.exists(cache_base):
        # ê¸°ì¡´ ìºì‹œ í˜„í™© í™•ì¸
        total_files = 0
        total_size = 0
        
        for root, dirs, files in os.walk(cache_base):
            cache_files = [f for f in files if f.endswith('.pkl')]
            total_files += len(cache_files)
            
            for file in cache_files:
                file_path = os.path.join(root, file)
                total_size += os.path.getsize(file_path)
        
        logger.info(f"ê¸°ì¡´ ìºì‹œ í˜„í™©: {total_files}ê°œ íŒŒì¼, {total_size / (1024*1024):.2f}MB")
    else:
        logger.info("ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ì‹¤í–‰ ì‹œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.")
    
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ì„¤ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

def run_health_check():
    """ìŠ¤íŠ¸ë¦¬ë° í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰"""
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ í—¬ìŠ¤ ì²´í¬ ì‹œì‘")
    
    try:
        # ë¨¼ì € ê¸°ë³¸ DB ì—°ê²° í™•ì¸
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸")
        try:
            from core.db import DatabaseManager
            test_db = DatabaseManager()
            if test_db.connection and test_db.connection.is_connected():
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ìƒ")
            else:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            test_db.close()
        except Exception as db_error:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {db_error}")
        
        # ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ë° ì‹¤í–‰
        scheduler = StreamingGlobalScheduler()
        
        # íšŒì‚¬ ê°ì§€
        scheduler.discover_and_register_companies()
        
        # í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰
        scheduler.run_health_check()
        
        # í—¬ìŠ¤ ëª¨ë‹ˆí„°ì—ì„œ ìƒì„¸ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰
        if hasattr(scheduler, 'health_monitor') and scheduler.health_monitor:
            logger.info("ìƒì„¸ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰")
            health_status = scheduler.health_monitor.perform_health_check()
            
            logger.info(f"ì „ì²´ í—¬ìŠ¤ ìƒíƒœ: {health_status['overall_status']}")
            
            # ì»´í¬ë„ŒíŠ¸ë³„ ìƒíƒœ ì¶œë ¥
            if 'components' in health_status:
                for component, status in health_status['components'].items():
                    status_text = status.get('status', 'unknown')
                    message = status.get('message', 'ì •ë³´ ì—†ìŒ')
                    logger.info(f"  {component}: {status_text} - {message}")
        
        # ì „ì²´ ìƒíƒœ í™•ì¸
        status = scheduler.get_status()
        logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ: {status.get('status', 'unknown')}")
        logger.info(f"ì•„í‚¤í…ì²˜: {status.get('architecture', 'unknown')}")
        
        if 'total_companies' in status:
            logger.info(f"ë“±ë¡ëœ íšŒì‚¬ ìˆ˜: {status['total_companies']}")
            
            for company, info in status.get('companies', {}).items():
                logger.info(f"íšŒì‚¬ '{company}': ë””ë°”ì´ìŠ¤ {info.get('devices', 0)}ê°œ")
                if info.get('device_list'):
                    logger.info(f"  ë””ë°”ì´ìŠ¤ ëª©ë¡: {', '.join(info['device_list'])}")
        
        # ìºì‹œ ìƒíƒœ í™•ì¸
        if 'cache_summary' in status:
            cache_info = status['cache_summary']
            logger.info(f"ì „ì²´ ìºì‹œ: {cache_info.get('total_files', 0)}ê°œ íŒŒì¼, {cache_info.get('total_size_mb', 0)}MB")
        
        if 'error' in status:
            logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì˜¤ë¥˜: {status['error']}")
        
        scheduler.stop()
        
    except Exception as e:
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ í—¬ìŠ¤ ì²´í¬ ì™„ë£Œ")

def run_status_check():
    """ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í™•ì¸"""
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹œì‘")
    
    try:
        scheduler = StreamingGlobalScheduler()
        
        # ì´ˆê¸° ì„¤ì • ì‹¤í–‰ (íšŒì‚¬ ê°ì§€)
        scheduler.discover_and_register_companies()
        
        # ìƒíƒœ ì •ë³´ ì¶œë ¥
        status = scheduler.get_status()
        
        logger.info(f"ì‹œìŠ¤í…œ ìƒíƒœ: {status['status']}")
        logger.info(f"ì•„í‚¤í…ì²˜: {status.get('architecture', 'streaming')}")
        logger.info(f"ì´ íšŒì‚¬ ìˆ˜: {status['total_companies']}")
        
        if status['total_companies'] > 0:
            logger.info("íšŒì‚¬ë³„ ìƒì„¸ ì •ë³´:")
            for company, info in status['companies'].items():
                logger.info(f"  {company}:")
                logger.info(f"    ë””ë°”ì´ìŠ¤ ìˆ˜: {info['devices']}")
                if info['device_list']:
                    logger.info(f"    ë””ë°”ì´ìŠ¤ ëª©ë¡: {', '.join(info['device_list'])}")
                else:
                    logger.info(f"    ë””ë°”ì´ìŠ¤ ëª©ë¡: ì—†ìŒ")
        else:
            logger.warning("ë“±ë¡ëœ íšŒì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            logger.info("InfluxDBì—ì„œ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ìºì‹œ ìƒíƒœ ì •ë³´
        if 'cache_summary' in status:
            cache_info = status['cache_summary']
            logger.info("ìºì‹œ í˜„í™©:")
            logger.info(f"  ì´ íŒŒì¼ ìˆ˜: {cache_info.get('total_files', 0)}ê°œ")
            logger.info(f"  ì´ í¬ê¸°: {cache_info.get('total_size_mb', 0)}MB")
        
        scheduler.stop()
        
    except Exception as e:
        logger.error(f"ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì™„ë£Œ")

def run_migration_setup():
    """ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤í–‰
        from scripts.streamlined_database_setup import create_streamlined_tables, insert_default_streaming_configs, validate_streaming_setup
        
        logger.info("1. ìŠ¤íŠ¸ë¦¬ë° í…Œì´ë¸” ìƒì„±")
        if not create_streamlined_tables():
            logger.error("ìŠ¤íŠ¸ë¦¬ë° í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
            return False
        
        logger.info("2. ìŠ¤íŠ¸ë¦¬ë° ê¸°ë³¸ ì„¤ì • ì‚½ì…")
        if not insert_default_streaming_configs():
            logger.error("ìŠ¤íŠ¸ë¦¬ë° ê¸°ë³¸ ì„¤ì • ì‚½ì… ì‹¤íŒ¨")
            return False
        
        logger.info("3. ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê²€ì¦")
        if not validate_streaming_setup():
            logger.error("ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
            return False
        
        # ê¸°ë³¸ ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        logger.info("4. ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±")
        cache_base = os.path.join(os.getcwd(), "cache")
        os.makedirs(cache_base, exist_ok=True)
        logger.info(f"ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {cache_base}")
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        logger.info("5. í™˜ê²½ë³€ìˆ˜ í™•ì¸")
        if not validate_streaming_environment():
            logger.error("í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜")
            return False
        
        logger.info("âœ… ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info("")
        logger.info("ğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info("  1. python main_streaming.py --mode scheduler")
        logger.info("  2. ë˜ëŠ” docker runìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰")
        logger.info("")
        logger.info("ğŸ“Š ì£¼ìš” ë³€ê²½ì‚¬í•­:")
        logger.info("  - InfluxDB ì§ì ‘ ì¡°íšŒë¡œ MySQL ë¶€í•˜ ê°ì†Œ")
        logger.info("  - íŒŒì¼ ìºì‹±ìœ¼ë¡œ ì¤‘ê°„ ë°ì´í„° íš¨ìœ¨ ê´€ë¦¬")
        logger.info("  - ë¶ˆí•„ìš”í•œ í…Œì´ë¸” ì œê±°ë¡œ DB ìµœì í™”")
        
        return True
        
    except Exception as e:
        logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def run_cache_cleanup_only():
    """ìºì‹œ ì •ë¦¬ë§Œ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ"""
    logger.info("ìºì‹œ ì •ë¦¬ ì „ìš© ëª¨ë“œ ì‹œì‘")
    
    try:
        scheduler = StreamingGlobalScheduler()
        
        # íšŒì‚¬ ê°ì§€ (ìºì‹œ ì •ë¦¬ ëŒ€ìƒ í™•ì¸ìš©)
        scheduler.discover_and_register_companies()
        
        # ìºì‹œ ì •ë¦¬ ì‹¤í–‰
        scheduler.run_cache_cleanup()
        
        logger.info("ìºì‹œ ì •ë¦¬ ì™„ë£Œ, í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        
    except Exception as e:
        logger.error(f"ìºì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())

def run_streaming_scheduler():
    """ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
    
    scheduler = StreamingGlobalScheduler()
    
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        success = scheduler.start()
        
        if success:
            logger.info("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ìƒ ì¢…ë£Œ")
        else:
            logger.error("ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„ì •ìƒ ì¢…ë£Œ")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•œ ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")
        scheduler.stop()
    except Exception as e:
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        scheduler.stop()
        raise

if __name__ == "__main__":
    main()